{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests will allow us to make a web request\n",
    "import requests\n",
    "# BeautifulSoup will allow us to easily parse the website's HTML code\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_colwidth = 2000\n",
    "pd.options.display.max_rows = 15000\n",
    "pd.options.display.max_columns = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Fetching Team IDs from the Ranking Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Using the ranking page to get the list of teams and their ids\n",
    "url2 = \"https://stats.ncaa.org/selection_rankings/nitty_gritties/27203\"\n",
    "header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "        }\n",
    "source = requests.get(url2, headers=header).text\n",
    "soup2 = BeautifulSoup(source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup2.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teams_df = pd.DataFrame(columns=['Team', 'Team_ID'])\n",
    "for team_id in soup2.find_all('a', class_=\"skipMask\", target=\"TEAM_PAGE\", href = True):\n",
    "#     print(team_id.text, team_id['href'].rsplit('/', 1)[-1])\n",
    "    teams_df = teams_df.append({'Team' : team_id.text, 'Team_ID' : team_id['href'].rsplit('/', 1)[-1]}, ignore_index=True)\n",
    "\n",
    "teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df.to_csv(\"teams_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Use the Team ID to get the Game IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "games_df = pd.DataFrame(columns=['Team', 'Team_ID', 'Game_ID', 'Date', 'Opp_Team', 'Opp_Team_ID'])\n",
    "\n",
    "for team_id in teams_df.Team_ID:\n",
    "    print(team_id)\n",
    "    \n",
    "    url_team = \"https://stats.ncaa.org/teams/\"+str(team_id)+\"\"\n",
    "    header_team = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',}\n",
    "    source = requests.get(url_team, headers=header_team).text\n",
    "    soup_team = BeautifulSoup(source, 'lxml')\n",
    "    \n",
    "#     game_date     = soup_team.find('td', text=re.compile('Game Date:')).find_next('td').text.strip()\n",
    "#     game_location = soup_team.find('td', text=re.compile('Location:')).find_next('td').text.strip()\n",
    "#     away_team     = (soup_team.find('a', class_=\"skipMask\", target=\"TEAMS_WIN\")['href'].rsplit('/', 1)[-1])\n",
    "#     home_team     = (soup_team.find_all('a', class_=\"skipMask\", target=\"TEAMS_WIN\")[-1]['href'].rsplit('/', 1)[-1])\n",
    "    \n",
    "    for game in soup_team.find_all('a', class_=\"skipMask\", target=\"BOX_SCORE_WINDOW\", href = True):\n",
    "#         print(game['href'].rsplit('/')[-2])\n",
    "        url_team2 = \"https://stats.ncaa.org\"+game['href']+\"\"\n",
    "        header_team2 = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',}\n",
    "        source2 = requests.get(url_team2, headers=header_team2).text\n",
    "        soup_team2 = BeautifulSoup(source2, 'lxml')\n",
    "        \n",
    "        for game2 in soup_team2.find_all('a', text='Play by Play', href = True):\n",
    "            games_df = games_df.append({'Team' : teams_df.loc[teams_df['Team_ID'] == team_id, 'Team'].iloc[0], \n",
    "                                    'Team_ID' : team_id,\n",
    "                                    'Game_ID' : game2['href'].rsplit('/')[-1]\n",
    "                                   }, ignore_index=True)\n",
    "\n",
    "games_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "games_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.to_csv(\"game_ids_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Fetching Play-by-Play Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pbp_recs=[{}]\n",
    "\n",
    "\n",
    "for game_id in games_df.Game_ID:\n",
    "    print(game_id)\n",
    "    \n",
    "    url_game = \"https://stats.ncaa.org/game/play_by_play/\"+str(game_id)\n",
    "    header_game = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',}\n",
    "    source = requests.get(url_game, headers=header_game).text\n",
    "    soup_game = BeautifulSoup(source, 'lxml')\n",
    "    \n",
    "    #print(soup_game.find_all('table', class_ = 'mytable', width = \"1000px\"))\n",
    "    \n",
    "    game_date     = soup_game.find('td', text=re.compile('Game Date:')).find_next('td').text.strip()\n",
    "    game_location = soup_game.find('td', text=re.compile('Location:')).find_next('td').text.strip()\n",
    "    away_team     = (soup_game.find('a', class_=\"skipMask\", target=\"TEAMS_WIN\")['href'].rsplit('/', 1)[-1])\n",
    "    home_team     = (soup_game.find_all('a', class_=\"skipMask\", target=\"TEAMS_WIN\")[-1]['href'].rsplit('/', 1)[-1])\n",
    "    \n",
    "    i=1 # Set the inning counter\n",
    "\n",
    "    # Loop through innings\n",
    "    for inning in soup_game.find_all('table', class_ = 'mytable', width = \"1000px\"):\n",
    "    # Loop through records in each inning, ignore tags with \"grey_heading\" class\n",
    "        for tag in inning.find_all('tr', class_=lambda x: x != 'grey_heading')[2:]:\n",
    "    # Check for the hyphen in the score, ignore \"blank\" rows without a score\n",
    "            if tag.find(string=re.compile(\"-\")):\n",
    "                score = tag.select('td:nth-of-type(2)')[0].string\n",
    "                \n",
    "    # Determine if data is for the top or bottom of the inning\n",
    "                if tag.select('td:nth-of-type(3)')[0].string is None:\n",
    "                    pbp_recs.append({'Game_ID' : game_id, 'Date' : game_date, 'Location' : game_location, 'awayTeam' : away_team, 'homeTeam' : home_team, 'inn' : i, 'topBottom' : 'top', 'text' : tag.select('td:nth-of-type(1)')[0].string, 'awayScore' : score.split('-')[0].strip(), 'homeScore' : score.split('-')[1].strip()})\n",
    "    #                print('Top ' + str(i) + '...' + tag.select('td:nth-of-type(1)')[0].string + ' ...Score ' + str(score))\n",
    "                else:\n",
    "                    pbp_recs.append({'Game_ID' : game_id, 'Date' : game_date, 'Location' : game_location, 'awayTeam' : away_team, 'homeTeam' : home_team, 'inn' : i, 'topBottom' : 'bot', 'text' : tag.select('td:nth-of-type(3)')[0].string, 'awayScore' : score.split('-')[0].strip(), 'homeScore' : score.split('-')[1].strip()})\n",
    "    #                print('Bottom ' + str(i) + '...' + tag.select('td:nth-of-type(3)')[0].string + ' ...Score ' + str(score))\n",
    "        \n",
    "        i+=1\n",
    "    # To create a dataframe: df = pd.DataFrame(pbp_recs)\n",
    "    \n",
    "pbp_df = pd.DataFrame(pbp_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbp_df = pd.DataFrame(pbp_recs)\n",
    "pbp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pbp_df = pbp_df.drop([0]).reset_index(drop=True)\n",
    "new_pbp_df = final_pbp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pbp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pbp_df.to_csv(\"raw_pbp_data_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pbp_df = pd.read_csv('raw_pbp_data_table.csv')\n",
    "final_pbp_df.head()\n",
    "new_pbp_df = final_pbp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Extracting Pay by Play data from 'Text' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pbp_df = new_pbp_df['text'].str.split(\";\",expand = True)\n",
    "new_pbp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for col,data in new_pbp_df.iteritems():\n",
    "    \n",
    "    player_name_list = []\n",
    "    action_list = []\n",
    "    balls_list = []\n",
    "    strikes_list = []\n",
    "    \n",
    "    for play in data.values:\n",
    "        if play and pd.isna(play) == False:\n",
    "#             print(play)\n",
    "\n",
    "            player_name = ''\n",
    "            action = ''\n",
    "            balls = ''\n",
    "            strikes = ''\n",
    "            \n",
    "\n",
    "            play = play.strip()\n",
    "\n",
    "            player_name_search = re.match(\"(^[A-Z](\\.|,)\\s+[A-Za-z]+)|(^[A-Za-z]+,\\s+[A-Z]\\.)\",play) # Example for name structure in the play text : A. Xyz OR Xyz, A. OR A, Xyz\n",
    "            if player_name_search : player_name = player_name_search.group(0).strip()\n",
    "\n",
    "            # searching for the action; extracting the balls and strikes\n",
    "            action = (play.replace(player_name,\"\")).strip()\n",
    "            score_status = re.search(\"\\([0-9]\\-[0-9](\\s)*[A-Z]*\\)\\.$\",action)\n",
    "\n",
    "            if score_status:\n",
    "                x = score_status.group(0)\n",
    "                search_score = re.findall(\"[0-9]\",x) # finding the balls and strikes in the text using regex\n",
    "                balls = search_score[0]\n",
    "                strikes = search_score[1]\n",
    "                action = (action.replace(x,\"\")).strip()\n",
    "\n",
    "#             print(player_name,action,balls,strikes)\n",
    "            \n",
    "            player_name_list.append(player_name)\n",
    "            action_list.append(action)\n",
    "            balls_list.append(balls)\n",
    "            strikes_list.append(strikes)\n",
    "        \n",
    "        else:\n",
    "            player_name_list.append(\"\")\n",
    "            action_list.append(\"\")\n",
    "            balls_list.append(\"\")\n",
    "            strikes_list.append(\"\")\n",
    "            \n",
    "    final_pbp_df['player_name_'+str(col)] = pd.Series(player_name_list)\n",
    "    final_pbp_df['action_'+str(col)] = pd.Series(action_list)\n",
    "    final_pbp_df['balls_'+str(col)] = pd.Series(balls_list)\n",
    "    final_pbp_df['strikes_'+str(col)] = pd.Series(strikes_list)\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pbp_df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pbp_df[final_pbp_df['player_name_3'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pbp_df.to_excel(\"pbp_v1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Extracting details (runs, outs, error, earned run) from the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_details_df = final_pbp_df\n",
    "pbp_details_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# for data in pbp_details_df.iteritems():\n",
    "    \n",
    "runs_scored_list = []\n",
    "outs_list = []\n",
    "error_flag = []\n",
    "run_credited_batter_flag = []\n",
    "\n",
    "for play in pbp_details_df['text'].values:\n",
    "    if play and pd.isna(play) == False:\n",
    "#         print(play)\n",
    "\n",
    "        play = play.strip()\n",
    "        runs_scored =''\n",
    "        outs = ''\n",
    "        errors = 0\n",
    "        runs_credited = ''\n",
    "\n",
    "\n",
    "        # Runs Scored & Unearned or not to batter\n",
    "        if re.search(\"([0-9]\\sRBI)\",play) :\n",
    "            runs = re.search(\"([0-9]\\sRBI)\",play).group(0)\n",
    "            runs_scored = int(runs.replace(\" RBI\",\"\"))\n",
    "            if re.search(\"(unearned)\",play) :\n",
    "                runs_credited = 0\n",
    "            else :\n",
    "                runs_credited = 1\n",
    "        elif re.search(\"(RBI)\",play) :\n",
    "            runs_scored = 1\n",
    "            if re.search(\"(unearned)\",play) :\n",
    "                runs_credited = 0\n",
    "            else :\n",
    "                runs_credited = 1\n",
    "\n",
    "\n",
    "\n",
    "        # Outs\n",
    "        if re.search(\"(into\\sdouble\\splay)\",play) :\n",
    "            outs = 2\n",
    "        elif re.findall(\"out\",play) :\n",
    "            outs = len(re.findall(\"out\",play))\n",
    "\n",
    "        \n",
    "        # Errors\n",
    "        if re.search(\"error\",play) :\n",
    "#             print(\"found error\")\n",
    "            errors = 1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        runs_scored_list.append(runs_scored)\n",
    "        outs_list.append(outs)\n",
    "        error_flag.append(errors)\n",
    "        run_credited_batter_flag.append(runs_credited)\n",
    "\n",
    "    else:\n",
    "        runs_scored_list.append(\"\")\n",
    "        outs_list.append(\"\")\n",
    "        error_flag.append(\"\")\n",
    "        run_credited_batter_flag.append(\"\")\n",
    "\n",
    "pbp_details_df['runs_scored'] = pd.Series(runs_scored_list)\n",
    "pbp_details_df['outs'] = pd.Series(outs_list)\n",
    "pbp_details_df['error_flag'] = pd.Series(error_flag)\n",
    "pbp_details_df['run_credited_batter_flag'] = pd.Series(run_credited_batter_flag)\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_details_df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pbp_details_df[pbp_details_df['error_flag'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp_details_df.to_csv(\"text_separated_pbp_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box Score Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell scrapes the simple \"box score\" for the game and puts it into a list of dictionaries (which...\n",
    "# is easily converted into a pandas dataframe!)\n",
    "\n",
    "game_inn_scores=[{}]\n",
    "\n",
    "# Get the gameid...\n",
    "gameid = int(soup.find('ul',class_ = \"level1\",id = \"root\").select(\"li > a\")[0]['href'].rsplit('/', 1)[-1])\n",
    "\n",
    "# Get the total number of innings in the game...\n",
    "num_innings = len(soup.find('table', class_ = 'mytable', width = \"40%\").tr.find_all())-4\n",
    "\n",
    "# Get the teamid of the AWAY team\n",
    "away_team = int(soup.find('a', class_=\"skipMask\", target=\"TEAMS_WIN\")['href'].rsplit('/', 1)[-1])\n",
    "# I'm definitely being a little sloppy here, but...\n",
    "# soup.find('a', class_=\"skipMask\", target=\"TEAMS_WIN\")['href']\n",
    "# ...is exactly equivalent to...\n",
    "# temp = soup.find('a', class_=\"skipMask\", target=\"TEAMS_WIN\")\n",
    "# temp['href']\n",
    "\n",
    "# Get the teamid of the HOME team\n",
    "home_team = int(soup.find_all('a', class_=\"skipMask\", target=\"TEAMS_WIN\")[-1]['href'].rsplit('/', 1)[-1])\n",
    "\n",
    "# Get the scores for the AWAY team\n",
    "away_inn_scores=soup.find('table', class_ = 'mytable', width = \"40%\").select('tr')[1].find_all('td')\n",
    "# Get the scores for the HOME team\n",
    "home_inn_scores=soup.find('table', class_ = 'mytable', width = \"40%\").select('tr')[2].find_all('td')\n",
    "\n",
    "# Capture the game notes (if there are any--and they may be multiple)\n",
    "# These may help us down the road to match pitchers with hitters in each at-bat\n",
    "notes = ''\n",
    "for tag in soup.find_all('table', align=\"center\", width=\"50%\")[0].find_all('td'):\n",
    "    if not tag.text.startswith('Weather:') and not tag.text.startswith('Game:'):\n",
    "        notes += tag.text + \";\"\n",
    "\n",
    "# Get the game date\n",
    "game_date = soup.find('td', text=re.compile('Game Date:')).find_next('td').text.strip()\n",
    "\n",
    "# Get the game location\n",
    "game_location = soup.find('td', text=re.compile('Location:')).find_next('td').text.strip()\n",
    "\n",
    "# Get rid of team name item\n",
    "away_inn_scores.pop(0)\n",
    "home_inn_scores.pop(0)\n",
    "\n",
    "# Remove and store total errors for game\n",
    "a_e = away_inn_scores.pop()\n",
    "h_e = home_inn_scores.pop()\n",
    "\n",
    "# Remove and store total hits for game\n",
    "a_h = away_inn_scores.pop()\n",
    "h_h = home_inn_scores.pop()\n",
    "\n",
    "# Remove and store total runs for game\n",
    "a_r = away_inn_scores.pop()\n",
    "h_r = home_inn_scores.pop()\n",
    "\n",
    "# Loop through innings and store values properly\n",
    "for i in range(len(away_inn_scores)):\n",
    "    game_inn_scores.append({'gameid' : gameid, 'teamid' : away_team, 'inn' : i + 1, 'runs_scored' : away_inn_scores[i].text})\n",
    "    game_inn_scores.append({'gameid' : gameid, 'teamid' : home_team, 'inn' : i + 1, 'runs_scored' : home_inn_scores[i].text})\n",
    "\n",
    "# To create a dataframe: df = pd.DataFrame(game_inn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_game_inn_scores = pd.DataFrame(game_inn_scores)\n",
    "df_game_inn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
