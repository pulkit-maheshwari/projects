{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\msi-nb\\appdata\\roaming\\python\\python38\\site-packages (2.7.1)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (2.1.1)\n",
      "Requirement already satisfied: service-identity>=18.1.0 in c:\\users\\msi-nb\\appdata\\roaming\\python\\python38\\site-packages (from scrapy) (21.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (20.4)\n",
      "Requirement already satisfied: tldextract in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (3.4.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\msi-nb\\appdata\\roaming\\python\\python38\\site-packages (from scrapy) (0.2.1)\n",
      "Requirement already satisfied: lxml>=4.3.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (4.6.1)\n",
      "Requirement already satisfied: cryptography>=3.3 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (38.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (1.7.0)\n",
      "Requirement already satisfied: zope.interface>=5.1.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (5.1.2)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (1.2.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5; platform_python_implementation == \"CPython\" in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (2.0.6)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (0.7.0)\n",
      "Requirement already satisfied: Twisted>=18.9.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (22.10.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\msi-nb\\appdata\\roaming\\python\\python38\\site-packages (from scrapy) (1.0.6)\n",
      "Requirement already satisfied: pyOpenSSL>=21.0.0 in c:\\users\\msi-nb\\appdata\\roaming\\python\\python38\\site-packages (from scrapy) (22.1.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from scrapy) (1.6.2)\n",
      "Requirement already satisfied: six in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (1.15.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from service-identity>=18.1.0->scrapy) (20.3.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\msi-nb\\appdata\\roaming\\python\\python38\\site-packages (from service-identity>=18.1.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\msi-nb\\appdata\\roaming\\python\\python38\\site-packages (from service-identity>=18.1.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from packaging->scrapy) (2.4.7)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (2.28.1)\n",
      "Requirement already satisfied: idna in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (2.10)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from tldextract->scrapy) (3.0.12)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from cryptography>=3.3->scrapy) (1.14.3)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (4.3.0)\n",
      "Requirement already satisfied: twisted-iocpsupport<2,>=1.0.2; platform_system == \"Windows\" in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (1.0.2)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from Twisted>=18.9.0->scrapy) (22.10.0)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\msi-nb\\appdata\\roaming\\python\\python38\\site-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.13)\n",
      "Requirement already satisfied: pycparser in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.3->scrapy) (2.20)\n",
      "Requirement already satisfied: driver in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (0.1.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\msi-nb\\anaconda3\\lib\\site-packages (from driver) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy\n",
    "!pip install driver\n",
    "# requests will allow us to make a web request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# BeautifulSoup will allow us to easily parse the website's HTML code\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "# Import a scrapy Selector\n",
    "from scrapy import Selector\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import driver\n",
    "from scrapy import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_name</th>\n",
       "      <th>team_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Villanova</td>\n",
       "      <td>532566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>532568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>532715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Texas Southern</td>\n",
       "      <td>532552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Toledo</td>\n",
       "      <td>532558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>South Alabama</td>\n",
       "      <td>532525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Furman</td>\n",
       "      <td>532683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Ga. Southern</td>\n",
       "      <td>532687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Hartford</td>\n",
       "      <td>532693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>532694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          team_name team_id\n",
       "0         Villanova  532566\n",
       "1          Virginia  532568\n",
       "2            Kansas  532715\n",
       "3    Texas Southern  532552\n",
       "4            Toledo  532558\n",
       "..              ...     ...\n",
       "296   South Alabama  532525\n",
       "297          Furman  532683\n",
       "298    Ga. Southern  532687\n",
       "299        Hartford  532693\n",
       "300         Harvard  532694\n",
       "\n",
       "[301 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################ Get the team name and team_id for 2021-2022 season, if you want to change season, just change \n",
    "url = \"https://stats.ncaa.org/selection_rankings/nitty_gritties/27203\"\n",
    "headers = {\n",
    "\"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Edg/108.0.1462.54\"\n",
    "       }      \n",
    "resp=requests.get(url,headers=headers)\n",
    "\n",
    "html = requests.get( url,headers=headers ).content\n",
    "# Create the Selector object sel from html\n",
    "sel = Selector( text=html )\n",
    "useful_info = sel.xpath('//html//body[@id=\"body\"]//a[@target=\"TEAM_PAGE\"and @class=\"skipMask\"]')\n",
    "useful_info\n",
    "text = useful_info.xpath('./text()').extract()\n",
    "href = useful_info.xpath('./@href').extract()\n",
    "text\n",
    "href\n",
    "team = pd.DataFrame(text)\n",
    "team=team.rename(columns = {0:\"team_name\"})\n",
    "href = pd.DataFrame(href)\n",
    "href=href.rename(columns = {0:\"team_id\"})\n",
    "team[\"team_id\"]=href\n",
    "\n",
    "team[\"team_id\"]=team['team_id'].map(lambda x: str(x)[7:])\n",
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = len(team.index)\n",
    "df_pbp= pd.DataFrame(columns=[\"gameid\",\"date\",\"location\",\"awayTeam\",\"homeTeam\",\"inn\",\"topBottom\",\"text\",\"awayScore\",\"homeScore\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://stats.ncaa.org/teams/532566\n",
      "https://stats.ncaa.org/teams/532568\n",
      "https://stats.ncaa.org/teams/532715\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7390be5decbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         headers = {\"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Edg/108.0.1462.54\"\n\u001b[0;32m     35\u001b[0m            }      \n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mhtml3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0murl3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    585\u001b[0m         }\n\u001b[0;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1040\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mtls_in_tls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    175\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(number):\n",
    "    team_idd = team.at[t,\"team_id\"]\n",
    "    url2 = \"https://stats.ncaa.org/teams/\"+str(team_idd)+\"\"\n",
    "    print(url2)\n",
    "    headers = {\"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Edg/108.0.1462.54\"\n",
    "       }      \n",
    "    resp=requests.get(url2,headers=headers)\n",
    "    html2 = requests.get( url2,headers=headers ).content\n",
    "    # Create the Selector object sel from html\n",
    "    sel2 = Selector( text=html2 )\n",
    "    specific_info = sel2.xpath('//html//a[@target=\"BOX_SCORE_WINDOW\"and @class=\"skipMask\"]')\n",
    "    specific_info\n",
    "\n",
    "    majorteam_info = sel2.xpath('//html//div[@id=\"facility_div\"]/div/@id').extract_first()\n",
    "    majorteam_info\n",
    "    href2 = specific_info.xpath('./@href').extract()\n",
    "    href2\n",
    "\n",
    "    href2 = pd.DataFrame(href2)\n",
    "    href2=href2.rename(columns={0:\"contest_id\"})\n",
    "    href2[\"team_id\"]=majorteam_info\n",
    "    href2[\"contest_id\"]= href2['contest_id'].map(lambda x: str(x)[10:17])\n",
    "    href2[\"team_id\"]=href2['team_id'].map(lambda x: str(x)[12:])\n",
    "    \n",
    "    contest_info = href2\n",
    "    contest_info\n",
    "    \n",
    "    n_c =len(contest_info)\n",
    "    n_c\n",
    "    \n",
    "    for q in range(n_c):\n",
    "        contest_idd = contest_info.at[q,\"contest_id\"]\n",
    "        url3 = \"https://stats.ncaa.org/contests/\"+str(contest_idd)+\"/box_score\"\n",
    "        headers = {\"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Edg/108.0.1462.54\"\n",
    "           }      \n",
    "        resp=requests.get(url3,headers=headers)\n",
    "    \n",
    "        html3 = requests.get( url3,headers=headers ).content\n",
    "        # Create the Selector object sel from html\n",
    "        sel3 = Selector( text=html3 )\n",
    "        specific_info = sel3.xpath('//html//ul[@class=\"level1\"]//li[3]/a/@href').extract()\n",
    "        specific_info=pd.DataFrame(specific_info).rename(columns = {0:\"game_id\"})        \n",
    "        specific_info['game_id'] = specific_info['game_id'].apply(lambda x: x.split('/')[-1])\n",
    "    \n",
    "        m=specific_info.iloc[0,0]\n",
    "        \n",
    "    \n",
    "    \n",
    "        url = \"https://stats.ncaa.org/game/play_by_play/\"+str(m)+\"\"\n",
    "        header = { 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',\n",
    "        }\n",
    "        source = requests.get(url, headers=header).text\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "        \n",
    "        \n",
    "\n",
    "        game_inn_scores=[{}]\n",
    "\n",
    "        # Get the gameid...\n",
    "        gameid = int(soup.find('ul',class_ = \"level1\",id = \"root\").select(\"li > a\")[0]['href'].rsplit('/', 1)[-1])\n",
    "\n",
    "        # Get the total number of innings in the game...\n",
    "        num_innings = len(soup.find('table', class_ = 'mytable', width = \"40%\").tr.find_all())-4\n",
    "\n",
    "        # Get the teamid of the AWAY team\n",
    "        away_team = int(soup.find('a', class_=\"skipMask\", target=\"TEAMS_WIN\")['href'].rsplit('/', 1)[-1])\n",
    "        # I'm definitely being a little sloppy here, but...\n",
    "        # soup.find('a', class_=\"skipMask\", target=\"TEAMS_WIN\")['href']\n",
    "        # ...is exactly equivalent to...\n",
    "        # temp = soup.find('a', class_=\"skipMask\", target=\"TEAMS_WIN\")\n",
    "        # temp['href']\n",
    "\n",
    "        # Get the teamid of the HOME team\n",
    "        home_team = int(soup.find_all('a', class_=\"skipMask\", target=\"TEAMS_WIN\")[-1]['href'].rsplit('/', 1)[-1])\n",
    "\n",
    "        # Get the scores for the AWAY team\n",
    "        away_inn_scores=soup.find('table', class_ = 'mytable', width = \"40%\").select('tr')[1].find_all('td')\n",
    "        # Get the scores for the HOME team\n",
    "        home_inn_scores=soup.find('table', class_ = 'mytable', width = \"40%\").select('tr')[2].find_all('td')\n",
    "\n",
    "        # Capture the game notes (if there are any--and they may be multiple)\n",
    "        # These may help us down the road to match pitchers with hitters in each at-bat\n",
    "        notes = ''\n",
    "        for tag in soup.find_all('table', align=\"center\", width=\"50%\")[0].find_all('td'):\n",
    "            if not tag.text.startswith('Weather:') and not tag.text.startswith('Game:'):\n",
    "                notes += tag.text + \";\"\n",
    "\n",
    "        # Get the game date\n",
    "        game_date = soup.find('td', text=re.compile('Game Date:')).find_next('td').text.strip()\n",
    "\n",
    "        # Get the game location\n",
    "        game_location = soup.find('td', text=re.compile('Location:')).find_next('td').text.strip()\n",
    "\n",
    "        # Get rid of team name item\n",
    "        away_inn_scores.pop(0)\n",
    "        home_inn_scores.pop(0)\n",
    "\n",
    "        # Remove and store total errors for game\n",
    "        a_e = away_inn_scores.pop()\n",
    "        h_e = home_inn_scores.pop()\n",
    "\n",
    "        # Remove and store total hits for game\n",
    "        a_h = away_inn_scores.pop()\n",
    "        h_h = home_inn_scores.pop()\n",
    "\n",
    "        # Remove and store total runs for game\n",
    "        a_r = away_inn_scores.pop()\n",
    "        h_r = home_inn_scores.pop()\n",
    "\n",
    "        # Loop through innings and store values properly\n",
    "        for k in range(len(away_inn_scores)):\n",
    "            game_inn_scores.append({'gameid' : gameid, 'teamid' : away_team, 'inn' : k + 1, 'runs_scored' : away_inn_scores[k].text})\n",
    "            game_inn_scores.append({'gameid' : gameid, 'teamid' : home_team, 'inn' : k + 1, 'runs_scored' : home_inn_scores[k].text})\n",
    "\n",
    "        # To create a dataframe: df = pd.DataFrame(game_inn_scores)\n",
    "        \n",
    "       \n",
    "        # Scrape the play-by-play data\n",
    "        pbp_recs=[{}]\n",
    "        # Set the inning counter\n",
    "        i=1\n",
    "        # Loop through innings\n",
    "        for inning in soup.find_all('table', class_ = 'mytable', width = \"1000px\"):\n",
    "        # Loop through records in each inning, ignore tags with \"grey_heading\" class\n",
    "            for tag in inning.find_all('tr', class_=lambda x: x != 'grey_heading')[2:]:\n",
    "        # Check for the hyphen in the score, ignore \"blank\" rows without a score\n",
    "                if tag.find(string=re.compile(\"-\")):\n",
    "                    score = tag.select('td:nth-of-type(2)')[0].string\n",
    "        # Determine if data is for the top or bottom of the inning\n",
    "                    if tag.select('td:nth-of-type(3)')[0].string is None:\n",
    "                        pbp_recs.append({'gameid' : gameid, 'date' : game_date, 'location' : game_location, 'awayTeam' : away_team, 'homeTeam' : home_team, 'inn' : i, 'topBottom' : 'top', 'text' : tag.select('td:nth-of-type(1)')[0].string, 'awayScore' : score.split('-')[0].strip(), 'homeScore' : score.split('-')[1].strip()})\n",
    "        #                print('Top ' + str(i) + '...' + tag.select('td:nth-of-type(1)')[0].string + ' ...Score ' + str(score))\n",
    "                    else:\n",
    "                        pbp_recs.append({'gameid' : gameid, 'date' : game_date, 'location' : game_location, 'awayTeam' : away_team, 'homeTeam' : home_team, 'inn' : i, 'topBottom' : 'bot', 'text' : tag.select('td:nth-of-type(3)')[0].string, 'awayScore' : score.split('-')[0].strip(), 'homeScore' : score.split('-')[1].strip()})\n",
    "        #                print('Bottom ' + str(i) + '...' + tag.select('td:nth-of-type(3)')[0].string + ' ...Score ' + str(score))\n",
    "            i+=1\n",
    "        # To create a dataframe: df = pd.DataFrame(pbp_recs)\n",
    "        df_pbp=df_pbp.append(pbp_recs)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameid</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>awayTeam</th>\n",
       "      <th>homeTeam</th>\n",
       "      <th>inn</th>\n",
       "      <th>topBottom</th>\n",
       "      <th>text</th>\n",
       "      <th>awayScore</th>\n",
       "      <th>homeScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5201718.0</td>\n",
       "      <td>02/11/2022</td>\n",
       "      <td>Atlanta, Ga.</td>\n",
       "      <td>532566.0</td>\n",
       "      <td>532689.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>top</td>\n",
       "      <td>Giampolo, A. struck out swinging.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5201718.0</td>\n",
       "      <td>02/11/2022</td>\n",
       "      <td>Atlanta, Ga.</td>\n",
       "      <td>532566.0</td>\n",
       "      <td>532689.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>top</td>\n",
       "      <td>Rauch, P. singled up the middle.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5201718.0</td>\n",
       "      <td>02/11/2022</td>\n",
       "      <td>Atlanta, Ga.</td>\n",
       "      <td>532566.0</td>\n",
       "      <td>532689.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>top</td>\n",
       "      <td>Smith, C. walked; Rauch, P. advanced to second.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5201718.0</td>\n",
       "      <td>02/11/2022</td>\n",
       "      <td>Atlanta, Ga.</td>\n",
       "      <td>532566.0</td>\n",
       "      <td>532689.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>top</td>\n",
       "      <td>Rauch, P. advanced to third.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10622</th>\n",
       "      <td>5241484.0</td>\n",
       "      <td>03/20/2022</td>\n",
       "      <td>Lawrence, Kan.</td>\n",
       "      <td>532529.0</td>\n",
       "      <td>532715.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>top</td>\n",
       "      <td>Bruno, Olivia to p.</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10623</th>\n",
       "      <td>5241484.0</td>\n",
       "      <td>03/20/2022</td>\n",
       "      <td>Lawrence, Kan.</td>\n",
       "      <td>532529.0</td>\n",
       "      <td>532715.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>top</td>\n",
       "      <td>/  for Hamilton, Kasey.</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>5241484.0</td>\n",
       "      <td>03/20/2022</td>\n",
       "      <td>Lawrence, Kan.</td>\n",
       "      <td>532529.0</td>\n",
       "      <td>532715.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>top</td>\n",
       "      <td>Rylee Nicholson struck out looking.</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>5241484.0</td>\n",
       "      <td>03/20/2022</td>\n",
       "      <td>Lawrence, Kan.</td>\n",
       "      <td>532529.0</td>\n",
       "      <td>532715.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>top</td>\n",
       "      <td>Jordyn Pender grounded out to 1b unassisted.</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10626</th>\n",
       "      <td>5241484.0</td>\n",
       "      <td>03/20/2022</td>\n",
       "      <td>Lawrence, Kan.</td>\n",
       "      <td>532529.0</td>\n",
       "      <td>532715.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>top</td>\n",
       "      <td>Gabby Moser popped up to 1b.</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10627 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          gameid        date        location  awayTeam  homeTeam  inn  \\\n",
       "0            NaN         NaN             NaN       NaN       NaN  NaN   \n",
       "1      5201718.0  02/11/2022    Atlanta, Ga.  532566.0  532689.0  1.0   \n",
       "2      5201718.0  02/11/2022    Atlanta, Ga.  532566.0  532689.0  1.0   \n",
       "3      5201718.0  02/11/2022    Atlanta, Ga.  532566.0  532689.0  1.0   \n",
       "4      5201718.0  02/11/2022    Atlanta, Ga.  532566.0  532689.0  1.0   \n",
       "...          ...         ...             ...       ...       ...  ...   \n",
       "10622  5241484.0  03/20/2022  Lawrence, Kan.  532529.0  532715.0  7.0   \n",
       "10623  5241484.0  03/20/2022  Lawrence, Kan.  532529.0  532715.0  7.0   \n",
       "10624  5241484.0  03/20/2022  Lawrence, Kan.  532529.0  532715.0  7.0   \n",
       "10625  5241484.0  03/20/2022  Lawrence, Kan.  532529.0  532715.0  7.0   \n",
       "10626  5241484.0  03/20/2022  Lawrence, Kan.  532529.0  532715.0  7.0   \n",
       "\n",
       "      topBottom                                             text awayScore  \\\n",
       "0           NaN                                              NaN       NaN   \n",
       "1           top                Giampolo, A. struck out swinging.         0   \n",
       "2           top                 Rauch, P. singled up the middle.         0   \n",
       "3           top  Smith, C. walked; Rauch, P. advanced to second.         0   \n",
       "4           top                     Rauch, P. advanced to third.         0   \n",
       "...         ...                                              ...       ...   \n",
       "10622       top                              Bruno, Olivia to p.         1   \n",
       "10623       top                          /  for Hamilton, Kasey.         1   \n",
       "10624       top              Rylee Nicholson struck out looking.         1   \n",
       "10625       top     Jordyn Pender grounded out to 1b unassisted.         1   \n",
       "10626       top                     Gabby Moser popped up to 1b.         1   \n",
       "\n",
       "      homeScore  \n",
       "0           NaN  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "10622         6  \n",
       "10623         6  \n",
       "10624         6  \n",
       "10625         6  \n",
       "10626         6  \n",
       "\n",
       "[10627 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pbp.drop_duplicates(inplace=True) \n",
    "df_pbp.reset_index(drop=True, inplace=True)\n",
    "df_pbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pbp.to_csv('pbp_data.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
